{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d47e4fd5",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.fft import rfft2, irfft2\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "sys.path.append(os.path.abspath(os.path.join(current_dir, '..')))\n",
    "h5_files = glob.glob(os.path.join(\"..\\\\output\", \"*.h5\"))\n",
    "\n",
    "y, Hs, Tp, modes, time, length, x = None, None, None, None, None, None, None\n",
    "\n",
    "with h5py.File(\"Z:\\\\files\\\\simulation_2d_compressed.h5\", \"r\") as data:\n",
    "    y = data[\"y\"][:]\n",
    "    Hs = data.attrs[\"Hs\"]\n",
    "    Tp = data.attrs[\"Tp\"]\n",
    "\n",
    "    modes = data.attrs[\"modes\"]\n",
    "    length = data.attrs[\"length\"]\n",
    "    Ta = data.attrs[\"Ta\"]\n",
    "    x = np.linspace(0, length, 2*modes)\n",
    "\n",
    "index = 100\n",
    "y = y[index:index+600, 0, : :].astype(np.complex64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb493a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_hat = y.copy()\n",
    "\n",
    "modes = eta_hat.shape[-2] // 2\n",
    "x = np.linspace(0, length, 2*modes)\n",
    "\n",
    "X, Y = np.meshgrid(x, x)\n",
    "mask = ((X-1500)**2+(Y-1500)**2) <= 200**2\n",
    "\n",
    "mask_i_left = []\n",
    "mask_i_right = []\n",
    "mask_i = []\n",
    "mask_j = []\n",
    "\n",
    "I, J = np.meshgrid(np.arange(0, 2*modes), np.arange(0, 2*modes))\n",
    "for i in range(2*modes):\n",
    "    for j in range(2*modes):\n",
    "        if not mask[i, j]:\n",
    "            continue\n",
    "\n",
    "        for k in range(modes):\n",
    "            if not mask[modes+k, j]:\n",
    "                mask_i.append(i)\n",
    "                mask_j.append(j)\n",
    "                mask_i_left.append(modes+k)\n",
    "                mask_i_right.append(modes-k-1)\n",
    "                break\n",
    "\n",
    "mask_i = np.array(mask_i)\n",
    "mask_j = np.array(mask_j)\n",
    "mask_i_left = np.array(mask_i_left)\n",
    "mask_i_right = np.array(mask_i_right)\n",
    "\n",
    "eta = irfft2(eta_hat).astype(np.float32)\n",
    "eta[:, mask_i, mask_j] = (eta[:, mask_i_left, mask_j] + eta[:, mask_i_right, mask_j])*0.5\n",
    "eta_hat = rfft2(eta).astype(np.complex64)\n",
    "eta_hat[:, 204:, :] = 0\n",
    "eta_hat[:, :, 204:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4630c362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(383, 7, 1024, 1024) (383, 1024, 1024)\n",
      "(96, 7, 1024, 1024) (96, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "prediction_time = 60 # 140 sec\n",
    "measure_time = 60 # one minute\n",
    "num_measurements = 6\n",
    "step = int(measure_time / num_measurements)\n",
    "train_percentage = 0.8\n",
    "\n",
    "X = eta_hat[:-prediction_time]\n",
    "y = eta_hat[prediction_time+measure_time:-1]\n",
    "\n",
    "X = irfft2(X)\n",
    "y = irfft2(y)\n",
    "\n",
    "X = np.stack([\n",
    "    X[0*step:-measure_time+0*step-1],\n",
    "    X[1*step:-measure_time+1*step-1],\n",
    "    X[2*step:-measure_time+2*step-1],\n",
    "    X[3*step:-measure_time+3*step-1],\n",
    "    X[4*step:-measure_time+4*step-1],\n",
    "    X[5*step:-measure_time+5*step-1],\n",
    "    X[6*step:-measure_time+6*step-1],\n",
    "], axis=1)\n",
    "\n",
    "X_train = X[:int(X.shape[0]*train_percentage), :, :]\n",
    "X_test = X[int(X.shape[0]*train_percentage):, :, :]\n",
    "y_train = y[:int(y.shape[0]*train_percentage), :]\n",
    "y_test = y[int(y.shape[0]*train_percentage):, :]\n",
    "\n",
    "# Only need std to normalize\n",
    "\n",
    "std = np.std(X_train)\n",
    "X_train = X_train / std\n",
    "y_train = y_train / std\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb2eb7b0",
   "metadata": {
    "tags": [
     "hide_input",
     "hide_output"
    ]
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 9.43 GiB for an array with shape (345, 7, 1024, 1024) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(val_mask)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# to PyTorch tensors\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m X_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mval_mask\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     14\u001b[0m y_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(y_train[\u001b[38;5;241m~\u001b[39mval_mask])\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     16\u001b[0m X_v \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(X_train[val_mask])\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 9.43 GiB for an array with shape (345, 7, 1024, 1024) and data type float32"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from FNO import FNO2d\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "val_mask = np.zeros(X_train.shape[0], dtype=bool)\n",
    "val_mask[:int(0.1 * X_train.shape[0])] = True\n",
    "np.random.shuffle(val_mask)\n",
    "\n",
    "# to PyTorch tensors\n",
    "X_t = torch.from_numpy(X_train[~val_mask]).float()\n",
    "y_t = torch.from_numpy(y_train[~val_mask]).float()\n",
    "\n",
    "X_v = torch.from_numpy(X_train[val_mask]).float()\n",
    "y_v = torch.from_numpy(y_train[val_mask]).float()\n",
    "\n",
    "dataset = TensorDataset(X_t, y_t)\n",
    "loader  = DataLoader(dataset, batch_size=25, shuffle=True)\n",
    "\n",
    "dataset_val = TensorDataset(X_v, y_v)\n",
    "loader_val  = DataLoader(dataset_val, batch_size=25, shuffle=True)\n",
    "\n",
    "model = FNO2d(in_channels=7, out_channels=1, width=16, modes_height=30, modes_width=150, depth=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "early_stopping_rounds = 3\n",
    "\n",
    "early_stopping_count = 0\n",
    "best_loss = np.inf\n",
    "\n",
    "loss_mask = np.ones(y_train.shape[1:])\n",
    "loss_mask[mask] = 5\n",
    "loss_mask = torch.tensor(loss_mask, dtype=torch.float32).to(device)\n",
    "loss_correction = 4 * modes * modes\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1, 101):\n",
    "    total_loss = 0.0\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred * loss_mask, yb * loss_mask) * loss_correction / torch.sum(loss_mask)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg = total_loss / len(loader)\n",
    "\n",
    "    total_loss_val = 0.0\n",
    "    for xb, yb in loader_val:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred * loss_mask, yb * loss_mask) * loss_correction / torch.sum(loss_mask)\n",
    "        total_loss_val += loss.item()\n",
    "    avg_val = total_loss / len(loader_val)\n",
    "\n",
    "    if avg_val < best_loss:\n",
    "        best_loss = avg_val\n",
    "        early_stopping_count = 0\n",
    "        torch.save(model.state_dict(), f\"results/best_FNO_2d_circ.pt\")\n",
    "        print(f\"Epoch: {epoch}, Loss train - {avg:.6f}, Loss val - {avg_val:.6f} - Saving\")\n",
    "    else:\n",
    "        print(f\"Epoch: {epoch}, Loss train - {avg:.6f}, Loss val - {avg_val:.6f}\")\n",
    "        early_stopping_count += 1\n",
    "        if early_stopping_count > early_stopping_rounds:\n",
    "            print(\"early_stopping\")\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
