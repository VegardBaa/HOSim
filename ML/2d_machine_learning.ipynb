{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d47e4fd5",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.fft import rfft2, irfft2\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "sys.path.append(os.path.abspath(os.path.join(current_dir, '..')))\n",
    "h5_files = glob.glob(os.path.join(\"..\\\\output\", \"*.h5\"))\n",
    "\n",
    "y, Hs, Tp, modes, time, length, x = None, None, None, None, None, None, None\n",
    "\n",
    "with h5py.File(\"Z:\\\\files\\\\simulation_2d_compressed.h5\", \"r\") as data:\n",
    "    y = data[\"y\"][:]\n",
    "    Hs = data.attrs[\"Hs\"]\n",
    "    Tp = data.attrs[\"Tp\"]\n",
    "\n",
    "    modes = data.attrs[\"modes\"]\n",
    "    length = data.attrs[\"length\"]\n",
    "    Ta = data.attrs[\"Ta\"]\n",
    "    x = np.linspace(0, length, 2*modes)\n",
    "\n",
    "index = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "901b1644",
   "metadata": {},
   "outputs": [],
   "source": [
    "mHOS = 4\n",
    "\n",
    "eta_hat = y[index:, 0, : :].copy()\n",
    "modes = eta_hat.shape[-2] // 2\n",
    "x = np.linspace(0, length, 2*modes)\n",
    "\n",
    "mes_index_1 = np.argmin(np.abs(x - 1300))\n",
    "mes_index_2 = np.argmin(np.abs(x - 1700))\n",
    "\n",
    "eta = irfft2(eta_hat)\n",
    "eta[:, mes_index_1:mes_index_2, mes_index_1:mes_index_2] = 0\n",
    "\n",
    "##\n",
    "for i in range(mes_index_1, mes_index_2):\n",
    "    eta[0, mes_index_1:mes_index_2, i] = (eta[0, mes_index_1-1, i] + eta[0, mes_index_2+1, i]) * 0.5 # juks?\n",
    "##\n",
    "\n",
    "eta_hat = rfft2(eta).astype(np.complex64)\n",
    "\n",
    "# plt.plot(np.linspace(0, 1, 2*modes), np.fft.irfft2(eta_hat[0, :, :])[0, :])\n",
    "\n",
    "modes = eta_hat.shape[-2] // 2\n",
    "alias_mask = np.arange(modes+1) < (modes * 2 / (mHOS + 1) + 1) * 0.8\n",
    "alias_mask_long = np.concatenate((alias_mask, alias_mask[2:][::-1]))\n",
    "new_modes = np.sum(alias_mask)-1\n",
    "eta_hat = eta_hat[:, alias_mask_long, :]\n",
    "eta_hat = eta_hat[:, :, alias_mask]\n",
    "eta_hat *= new_modes * new_modes / (modes * modes)\n",
    "modes = new_modes\n",
    "\n",
    "# plt.plot(np.linspace(0, 1, 2*modes), np.fft.irfft2(eta_hat[0, :, :])[0, :])\n",
    "# plt.xlim(0, 0.1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4630c362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(624, 7, 328, 328) (624, 328, 328)\n",
      "(156, 7, 328, 328) (156, 328, 328)\n"
     ]
    }
   ],
   "source": [
    "prediction_time = 60 # 140 sec\n",
    "measure_time = 60 # one minute\n",
    "num_measurements = 6\n",
    "step = int(measure_time / num_measurements)\n",
    "train_percentage = 0.8\n",
    "\n",
    "X = eta_hat[:-prediction_time]\n",
    "y = eta_hat[prediction_time+measure_time:-1]\n",
    "\n",
    "X = irfft2(X)\n",
    "y = irfft2(y)\n",
    "\n",
    "X = np.stack([\n",
    "    X[0*step:-measure_time+0*step-1],\n",
    "    X[1*step:-measure_time+1*step-1],\n",
    "    X[2*step:-measure_time+2*step-1],\n",
    "    X[3*step:-measure_time+3*step-1],\n",
    "    X[4*step:-measure_time+4*step-1],\n",
    "    X[5*step:-measure_time+5*step-1],\n",
    "    X[6*step:-measure_time+6*step-1],\n",
    "], axis=1)\n",
    "\n",
    "X_train = X[:int(X.shape[0]*train_percentage), :, :]\n",
    "X_test = X[int(X.shape[0]*train_percentage):, :, :]\n",
    "y_train = y[:int(y.shape[0]*train_percentage), :]\n",
    "y_test = y[int(y.shape[0]*train_percentage):, :]\n",
    "\n",
    "# Only need std to normalize\n",
    "\n",
    "std = np.std(X_train)\n",
    "X_train = X_train / std\n",
    "y_train = y_train / std\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2eb7b0",
   "metadata": {
    "tags": [
     "hide_input",
     "hide_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss train - 0.744830, Loss val - 5.710367 - Saving\n",
      "Epoch: 2, Loss train - 0.218387, Loss val - 1.674300 - Saving\n",
      "Epoch: 3, Loss train - 0.110089, Loss val - 0.844014 - Saving\n",
      "Epoch: 4, Loss train - 0.091685, Loss val - 0.702916 - Saving\n",
      "Epoch: 5, Loss train - 0.081920, Loss val - 0.628054 - Saving\n",
      "Epoch: 6, Loss train - 0.074261, Loss val - 0.569333 - Saving\n",
      "Epoch: 7, Loss train - 0.067592, Loss val - 0.518209 - Saving\n",
      "Epoch: 8, Loss train - 0.061416, Loss val - 0.470853 - Saving\n",
      "Epoch: 9, Loss train - 0.056168, Loss val - 0.430618 - Saving\n",
      "Epoch: 10, Loss train - 0.051308, Loss val - 0.393364 - Saving\n",
      "Epoch: 11, Loss train - 0.046812, Loss val - 0.358890 - Saving\n",
      "Epoch: 12, Loss train - 0.042826, Loss val - 0.328331 - Saving\n",
      "Epoch: 13, Loss train - 0.039091, Loss val - 0.299698 - Saving\n",
      "Epoch: 14, Loss train - 0.035775, Loss val - 0.274274 - Saving\n",
      "Epoch: 15, Loss train - 0.032872, Loss val - 0.252015 - Saving\n",
      "Epoch: 16, Loss train - 0.030314, Loss val - 0.232404 - Saving\n",
      "Epoch: 17, Loss train - 0.028019, Loss val - 0.214816 - Saving\n",
      "Epoch: 18, Loss train - 0.026156, Loss val - 0.200528 - Saving\n",
      "Epoch: 19, Loss train - 0.024420, Loss val - 0.187217 - Saving\n",
      "Epoch: 20, Loss train - 0.022923, Loss val - 0.175743 - Saving\n",
      "Epoch: 21, Loss train - 0.021563, Loss val - 0.165313 - Saving\n",
      "Epoch: 22, Loss train - 0.020458, Loss val - 0.156842 - Saving\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from FNO import FNO2d\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "val_mask = np.zeros(X_train.shape[0], dtype=bool)\n",
    "val_mask[:int(0.1 * X_train.shape[0])] = True\n",
    "np.random.shuffle(val_mask)\n",
    "\n",
    "# to PyTorch tensors\n",
    "X_t = torch.from_numpy(X_train[~val_mask]).float()\n",
    "y_t = torch.from_numpy(y_train[~val_mask]).float()\n",
    "\n",
    "X_v = torch.from_numpy(X_train[val_mask]).float()\n",
    "y_v = torch.from_numpy(y_train[val_mask]).float()\n",
    "\n",
    "dataset = TensorDataset(X_t, y_t)\n",
    "loader  = DataLoader(dataset, batch_size=25, shuffle=True)\n",
    "\n",
    "dataset_val = TensorDataset(X_v, y_v)\n",
    "loader_val  = DataLoader(dataset_val, batch_size=25, shuffle=True)\n",
    "\n",
    "model = FNO2d(in_channels=7, out_channels=1, width=16, modes_height=30, modes_width=150, depth=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "early_stopping_rounds = 3\n",
    "\n",
    "early_stopping_count = 0\n",
    "best_loss = np.inf\n",
    "\n",
    "loss_mask = np.ones(y_train.shape[1:])\n",
    "loss_mask[mes_index_1:mes_index_2, mes_index_1:mes_index_2] = 5\n",
    "loss_mask = torch.tensor(loss_mask, dtype=torch.float32).to(device)\n",
    "loss_correction = 4 * modes * modes\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1, 101):\n",
    "    total_loss = 0.0\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred * loss_mask, yb * loss_mask) * loss_correction / torch.sum(loss_mask)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg = total_loss / len(loader)\n",
    "\n",
    "    total_loss_val = 0.0\n",
    "    for xb, yb in loader_val:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred * loss_mask, yb * loss_mask) * loss_correction / torch.sum(loss_mask)\n",
    "        total_loss_val += loss.item()\n",
    "    avg_val = total_loss / len(loader_val)\n",
    "\n",
    "    if avg_val < best_loss:\n",
    "        best_loss = avg_val\n",
    "        early_stopping_count = 0\n",
    "        torch.save(model.state_dict(), f\"results/best_FNO_2d.pt\")\n",
    "        print(f\"Epoch: {epoch}, Loss train - {avg:.6f}, Loss val - {avg_val:.6f} - Saving\")\n",
    "    else:\n",
    "        print(f\"Epoch: {epoch}, Loss train - {avg:.6f}, Loss val - {avg_val:.6f}\")\n",
    "        early_stopping_count += 1\n",
    "        if early_stopping_count > early_stopping_rounds:\n",
    "            print(\"early_stopping\")\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
